import os
import sys
import subprocess
import datasets
import pandas as pd

# ç¡®ä¿å½“å‰ç›®å½•åœ¨sys.pathä¸­ï¼Œä»¥ä¾¿å¯¼å…¥verl
sys.path.append(os.getcwd())

def extract_solution(solution_str):
    """ä»OpenR1-Mathæ•°æ®ä¸­æå–boxedç­”æ¡ˆã€‚
    OpenR1é€šå¸¸éµå¾ªDeepSeek R1æ ¼å¼ï¼Œç­”æ¡ˆåœ¨ \\boxed{} ä¸­ã€‚
    """
    if not solution_str:
        return ""
    
    idx = solution_str.rfind("\\boxed")
    if idx < 0:
        return solution_str
    
    content = solution_str[idx:]
    if content.startswith("\\boxed{"):
        count = 0
        start = 7 # len("\\boxed{")
        for i, char in enumerate(content[start:], start=start):
            if char == '{':
                count += 1
            elif char == '}':
                if count == 0:
                    return content[start:i]
                count -= 1
    
    return solution_str

def prepare_data(output_dir="data/openr1"):
    """
    ä¸‹è½½å¹¶é¢„å¤„ç† OpenR1-Math-220k å®Œæ•´æ•°æ®é›†ã€‚
    """
    print(f"æ­£åœ¨å‡†å¤‡æ•°æ®ï¼Œç›®æ ‡ç›®å½•: {output_dir}...")
    os.makedirs(output_dir, exist_ok=True)
    
    dataset_name = "open-r1/OpenR1-Math-220k"
    
    try:
        print(f"æ­£åœ¨åŠ è½½å®Œæ•´æ•°æ®é›†: {dataset_name}")
        # åŠ è½½å®Œæ•´æ•°æ®é›†
        dataset = datasets.load_dataset(dataset_name, split="train")
        print(f"æˆåŠŸåŠ è½½ {len(dataset)} æ¡æ ·æœ¬ã€‚")
    except Exception as e:
        print(f"åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
        return None, None

    system_prompt = "Please reason step by step and put your final answer within \\boxed{}."

    # å¤„ç†æ•°æ®
    processed_data = []
    # å³ä½¿æ˜¯å…¨é‡æ•°æ®ï¼Œä¸ºäº†æ¼”ç¤ºæ•ˆç‡ï¼Œæˆ‘ä»¬è¿™é‡Œä¹Ÿå¯ä»¥åªå–ä¸€éƒ¨åˆ†ï¼Œæˆ–è€…å…¨é‡
    # è€ƒè™‘åˆ° Qwen 0.5B è®­ç»ƒå¾ˆå¿«ï¼Œæˆ‘ä»¬å– 20000 æ¡åšæ¼”ç¤ºï¼Œè®©ä½ èƒ½åœ¨ä¸€ä¸ªå°æ—¶å†…çœ‹åˆ°æ˜æ˜¾å˜åŒ–
    # å¦‚æœä½ æƒ³è·‘å…¨é‡ 220kï¼Œæ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œåˆ‡ç‰‡å³å¯
    # dataset = dataset.select(range(20000)) 
    
    print(f"å¼€å§‹å¤„ç† {len(dataset)} æ¡æ•°æ®...")
    
    # æ‰¹é‡å¤„ç†ä»¥æé«˜é€Ÿåº¦
    def process_batch(batch):
        new_data = {
            "data_source": [],
            "prompt": [],
            "ability": [],
            "reward_model": [],
            "extra_info": []
        }
        for prob, sol in zip(batch['problem'], batch['solution']): # OpenR1 å­—æ®µå
            ground_truth = extract_solution(sol)
            prompt_messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prob}
            ]
            new_data["data_source"].append("lighteval/MATH")
            new_data["prompt"].append(prompt_messages)
            new_data["ability"].append("math")
            new_data["reward_model"].append({"style": "rule", "ground_truth": ground_truth})
            new_data["extra_info"].append({"split": "train"})
        return new_data

    # ä½¿ç”¨ map è¿›è¡Œå¹¶è¡Œå¤„ç† (å¦‚æœæ•°æ®é‡å¾ˆå¤§)
    # è¿™é‡Œä¸ºäº†ç®€å•ç›´æ¥è½¬ pandas
    # æ³¨æ„ï¼šOpenR1-Math-220k æ•°æ®å­—æ®µå¯èƒ½æ˜¯ 'problem' å’Œ 'solution' æˆ–è€… 'question' 'response'
    # æˆ‘ä»¬åšä¸€ä¸ªç®€å•çš„é€‚é…
    data_list = []
    for i, item in enumerate(dataset):
        if i % 10000 == 0:
            print(f"å·²å¤„ç† {i} æ¡...")
        
        q = item.get('problem', item.get('question'))
        a = item.get('solution', item.get('response'))
        
        if not q or not a: continue

        processed_data.append({
            "data_source": "lighteval/MATH",
            "prompt": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": q}
            ],
            "ability": "math",
            "reward_model": {
                "style": "rule", 
                "ground_truth": extract_solution(a)
            },
            "extra_info": {"split": "train", "index": i}
        })

    df = pd.DataFrame(processed_data)
    
    # 95% è®­ç»ƒï¼Œ5% éªŒè¯
    train_size = int(len(df) * 0.95)
    train_df = df.iloc[:train_size]
    test_df = df.iloc[train_size:]
    
    train_path = os.path.join(output_dir, "train.parquet")
    test_path = os.path.join(output_dir, "test.parquet")
    
    train_df.to_parquet(train_path)
    test_df.to_parquet(test_path)
    
    print(f"æ•°æ®å·²ä¿å­˜: è®­ç»ƒé›† {len(train_df)} æ¡, éªŒè¯é›† {len(test_df)} æ¡")
    return train_path, test_path

def main():
    # 1. å‡†å¤‡æ•°æ®
    train_file, test_file = prepare_data()
    if not train_file:
        print("æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œé€€å‡º")
        return

    # 2. è®¾ç½®è®­ç»ƒå‚æ•°
    model_path = "Qwen/Qwen2.5-0.5B-Instruct"
    
    # 3. æ„é€ å¯åŠ¨å‘½ä»¤
    # é’ˆå¯¹ 8x MI325 (256GB) çš„è±ªåé…ç½®
    cmd = [
        sys.executable, "-m", "verl.trainer.main_ppo",
        
        # --- ç®—æ³•æ ¸å¿ƒ ---
        "algorithm.adv_estimator=grpo",
        "algorithm.use_kl_in_reward=False",
        "algorithm.kl_ctrl.kl_coef=0.001",
        
        # --- æ•°æ®é…ç½® ---
        f"data.train_files={train_file}",
        f"data.val_files={test_file}",
        "data.train_batch_size=2048", # æ˜¾å­˜å·¨å¤§ï¼Œå¯ä»¥å¼€è¶…å¤§ Batch Size åŠ é€Ÿè®­ç»ƒ
        "data.max_prompt_length=2048", # å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦
        "data.max_response_length=2048", # å…è®¸æ›´é•¿çš„æ€ç»´é“¾
        
        # --- æ¨¡å‹é…ç½® ---
        f"actor_rollout_ref.model.path={model_path}",
        "actor_rollout_ref.model.use_remove_padding=True",
        
        # --- Rollout (æ¨ç†) é…ç½® ---
        # é‡‡æ ·æ•° N=16 (GRPO æ¨èå€¼ï¼Œæ˜¾å­˜è¶³å¤Ÿå¤§å¯ä»¥æ›´å¤§ï¼ŒåŸºçº¿æ›´ç¨³)
        "actor_rollout_ref.rollout.n=16", 
        "actor_rollout_ref.rollout.name=vllm",
        # MI325 256G æ˜¾å­˜æå¤§ï¼Œä¸éœ€è¦å¤ªåå•¬ï¼Œç»™ vLLM 0.4 è¶³å¤Ÿäº†ï¼Œå‰©ä¸‹çš„ç»™è®­ç»ƒ
        "actor_rollout_ref.rollout.gpu_memory_utilization=0.4", 
        "actor_rollout_ref.rollout.enforce_eager=True",
        # 0.5B æ¨¡å‹æå°ï¼Œå•å¡æ¨ç†ç»°ç»°æœ‰ä½™ï¼ŒTP=1 æ•ˆç‡æœ€é«˜
        # 8 å¡ç¯å¢ƒä¸‹ï¼ŒVerl ä¼šè‡ªåŠ¨å¼€å¯ Data Parallel æ¨ç† (8è·¯å¹¶å‘)
        "actor_rollout_ref.rollout.tensor_model_parallel_size=1",
        
        # --- Actor (è®­ç»ƒ) é…ç½® ---
        # FSDP è®­ç»ƒ
        "actor_rollout_ref.actor.ppo_mini_batch_size=512", # å¢å¤§ mini batch
        "actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=64", # 256G æ˜¾å­˜å¯ä»¥éšä¾¿å¼€
        "actor_rollout_ref.actor.use_kl_loss=True",
        "actor_rollout_ref.actor.kl_loss_coef=0.001",
        # æ˜¾å­˜è¶³å¤Ÿï¼Œå…³é—­ Offload ä»¥è·å¾—æè‡´é€Ÿåº¦
        "actor_rollout_ref.actor.fsdp_config.param_offload=False",
        "actor_rollout_ref.actor.fsdp_config.optimizer_offload=False",
        
        # --- Reference (å‚è€ƒæ¨¡å‹) é…ç½® ---
        "actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=64",
        # åŒæ ·å…³é—­ Ref æ¨¡å‹çš„ Offloadï¼Œè®©å®ƒå¸¸é©»æ˜¾å­˜ï¼Œè®¡ç®— KL æ•£åº¦é£å¿«
        "actor_rollout_ref.ref.fsdp_config.param_offload=False",
        
        # --- Rollout Log Prob é…ç½® ---
        "actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=64",
        
        # --- Trainer é…ç½® ---
        "trainer.total_epochs=3", # è·‘ 3 ä¸ª Epoch è§‚å¯Ÿæ•ˆæœ
        "trainer.n_gpus_per_node=8", # æ»¡è¡€ 8 å¡
        "trainer.nnodes=1",
        "trainer.project_name=verl_grpo_full_scale",
        "trainer.experiment_name=qwen_05b_math_8gpu",
        "trainer.logger=['console']",
        # æ¯ 10 ä¸ª step éªŒè¯ä¸€æ¬¡ï¼Œè®©ä½ èƒ½é¢‘ç¹çœ‹åˆ°æ•ˆæœå˜åŒ–
        "trainer.test_freq=10",
        "trainer.save_freq=-1", # ä¸ä¿å­˜ checkpoint
    ]
    
    print("\n" + "="*50)
    print("ğŸš€ å¼€å§‹è¿è¡Œ 8å¡ MI325 é«˜æ€§èƒ½ GRPO è®­ç»ƒ...")
    print(f"é…ç½®: å…¨é‡æ•°æ® | Batch=2048 | Rollout N=16 | Offload=OFF")
    print("="*50 + "\n")
    
    try:
        env = os.environ.copy()
        env["HYDRA_FULL_ERROR"] = "1"
        # AMD ç¯å¢ƒé€šå¸¸éœ€è¦è®¾ç½®è¿™ä¸ªï¼Œé˜²æ­¢å¤šè¿›ç¨‹æ­»é”
        env["NCCL_P2P_DISABLE"] = "1" 
        subprocess.run(cmd, check=True, env=env)
    except subprocess.CalledProcessError as e:
        print(f"\nè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    except KeyboardInterrupt:
        print("\nè®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­ã€‚")

if __name__ == "__main__":
    main()
