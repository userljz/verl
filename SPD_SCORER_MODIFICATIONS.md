# SPD Scorer å¯¹ verl åº“çš„ä¿®æ”¹è®°å½•

> **æ–‡æ¡£ç‰ˆæœ¬**: 1.5  
> **æ›´æ–°æ—¥æœŸ**: 2025-12-24  
> **ç›®çš„**: è¯¦ç»†è®°å½•ä¸ºå®ç° Speculative Decoding Scoring Model å¯¹åŸå§‹ verl åº“æ‰€åšçš„æ‰€æœ‰ä¿®æ”¹åŠæ–°å¢æ¨¡å—çš„åŠŸèƒ½è¯´æ˜ã€‚

---

## ğŸ“‹ ä¿®æ”¹æ¦‚è§ˆ

ä¸ºäº†å®ç° Speculative Decoding Scorer (SPD Scorer) çš„è®­ç»ƒï¼Œæˆ‘ä»¬åŸºäº verl æ¡†æ¶è¿›è¡Œäº†æ‰©å±•ã€‚æ‰€æœ‰çš„ä¿®æ”¹æ—¨åœ¨å®ç°ä»¥ä¸‹æ ¸å¿ƒæµç¨‹ï¼š
1.  **è‡ªå®šä¹‰æ¨¡å‹**: ä½¿ç”¨ `ScoringActor` æ›¿ä»£æ ‡å‡† LLMï¼Œè¾“å‡ºå¯¹ Draft Token çš„ Accept/Reject æ¦‚ç‡ã€‚
2.  **è‡ªå®šä¹‰ Rollout**: ä½¿ç”¨ `SPDRollout` æ‰§è¡Œä¸€æ¬¡ Forward å¹¶è¿›è¡Œ Bernoulli é‡‡æ ·ï¼Œè€Œéè‡ªå›å½’ç”Ÿæˆã€‚
3.  **è‡ªå®šä¹‰ Reward**: ä½¿ç”¨ `spd_scorer_reward` åŸºäº Draft æ¥å—é•¿åº¦å’Œæœ€ç»ˆç­”æ¡ˆæ­£ç¡®æ€§è®¡ç®—å¤æ‚å¥–åŠ±ã€‚
4.  **è‡ªå®šä¹‰æ•°æ®ç®¡é“**: é¢„å¤„ç† Context + Draft + Target çš„ç‰¹æ®Šè¾“å…¥æ ¼å¼ã€‚

### æ–‡ä»¶æ¸…å•

#### âœ¨ æ–°å¢æ–‡ä»¶ (New Files)
| æ–‡ä»¶è·¯å¾„ | æ¨¡å—/ç±» | è¯´æ˜ |
|:---|:---|:---|
| `spd_scorer.py` | `ScoringActor` | SPD Scorer æ¨¡å‹æ ¸å¿ƒå®ç°ã€‚æ–°å¢ `AutoModelForSPDScoring` å·¥å‚ç±»é€‚é… verl åŠ è½½æµç¨‹ã€‚ |
| `verl/workers/rollout/spd_rollout.py` | `SPDRollout` | è‡ªå®šä¹‰ Rollout ç­–ç•¥ï¼Œæ‰§è¡Œéè‡ªå›å½’çš„ Bernoulli é‡‡æ ·ï¼Œé›†æˆ vLLM è¿›è¡Œ Hybrid è¡¥å…¨éªŒè¯ã€‚ |
| `verl/utils/reward_score/spd_scorer_reward.py` | `compute_score` | è‡ªå®šä¹‰ Reward Functionï¼ŒåŸºäºæœ‰æ•ˆé•¿åº¦å’Œç­”æ¡ˆæ­£ç¡®æ€§è®¡ç®—å¤æ‚å¥–åŠ±ã€‚ |
| `verl/utils/dataset/spd_dataset.py` | `SPDRLHFDataset` | è‡ªå®šä¹‰ Datasetï¼Œæ”¯æŒé¢„è®¡ç®—çš„ `input_ids` å’Œç´¢å¼•åç§»ä¿®æ­£ã€‚ |
| `train_spd_scorer.py` | `run_training` | è®­ç»ƒå…¥å£è„šæœ¬ã€‚**åŒ…å« Monkey Patch é€»è¾‘** ä»¥å¼ºåˆ¶åŠ è½½ SPD æ¨¡å‹ã€‚ |
| `scripts/train_spd_scorer.sh` | Shell Script | è®­ç»ƒå¯åŠ¨è„šæœ¬ï¼Œé…ç½®ç¯å¢ƒå˜é‡ã€æ¨¡å‹è·¯å¾„ã€è®­ç»ƒè¶…å‚æ•°ã€‚DEBUG æ—¥å¿—çº§åˆ«ã€‚ |
| `scripts/train_spd_scorer_info.sh` | Shell Script | è®­ç»ƒå¯åŠ¨è„šæœ¬çš„ INFO æ—¥å¿—çº§åˆ«ç‰ˆæœ¬ï¼Œç”¨äºæ­£å¼å®éªŒå‡å°‘æ—¥å¿—è¾“å‡ºã€‚ |
| `verl/workers/rollout/spd_rollout_dep.py` | (Deprecated) | æ—§ç‰ˆ SPD Rollout å¤‡ä»½ï¼Œä¿ç•™ä¾›å‚è€ƒã€‚ |

#### âœï¸ ä¿®æ”¹æ–‡ä»¶ (Modified Files)
| æ–‡ä»¶è·¯å¾„ | ä¿®æ”¹å†…å®¹ | è¯´æ˜ |
|:---|:---|:---|
| `verl/utils/reward_score/__init__.py` | `default_compute_score` | æ³¨å†Œ `spd_scorer` æ•°æ®æºï¼Œåˆ†å‘å‚æ•°åˆ°æ–°çš„ Reward Functionã€‚ |
| `verl/workers/rollout/base.py` | `_ROLLOUT_REGISTRY` | æ³¨å†Œ `("spd", "sync")` å¯¹åº”çš„ Rollout ç±»ã€‚ |
| `verl/trainer/ppo/ray_trainer.py` | æ·»åŠ  Debug æ—¥å¿— | åœ¨æ•°æ®æµè½¬çš„å…³é”®èŠ‚ç‚¹ï¼ˆDataLoaderè¯»å–ã€Rewardè®¡ç®—å‰ï¼‰æ‰“å° Batch Sizeï¼Œç”¨äºéªŒè¯æ•°æ®ç»´åº¦å˜åŒ–ã€‚ |
| `verl/workers/actor/dp_actor.py` | æ·»åŠ  Debug æ—¥å¿— | åœ¨ `update_policy` æ–¹æ³•ä¸­æ·»åŠ è¯¦ç»†çš„è®­ç»ƒæŒ‡æ ‡æ—¥å¿— (advantages, log_prob, loss ç­‰)ï¼Œç”¨äºè°ƒè¯•ç­–ç•¥æ›´æ–°è¿‡ç¨‹ã€‚ |
| `verl/workers/reward_manager/batch.py` | `verify` æ–¹æ³• | ä¿®æ”¹å‚æ•°ä¼ é€’ï¼Œæ–°å¢ `prompt_ids`ã€`response_ids`ã€`attention_mask`ã€`batch_tensors` ä¼ é€’ç»™ reward functionï¼Œæ”¯æŒ SPD Scorer è®¿é—®å®Œæ•´ Batch Tensorã€‚ |

---

## ğŸ” è¯¦ç»†æ¨¡å—è¯´æ˜

### 1. æ¨¡å‹å±‚: `spd_scorer.py`

æ­¤æ–‡ä»¶å®šä¹‰äº† SPD Scorer çš„æ¨¡å‹æ¶æ„ã€‚æ¨¡å‹åŸºäº Llama-3-8B (Backbone) + LoRA + Score Headã€‚

*   **`ScoringModelConfig` (Class)**: é…ç½®ç±»ï¼Œå®šä¹‰äº† `hidden_size`, `lora_rank`, `mismatch_logit_value` ç­‰è¶…å‚æ•°ã€‚
*   **`SPDInputData` (Class)**: SPD æ¨¡å‹çš„è¾“å…¥æ•°æ®ç»“æ„ï¼ˆdataclassï¼‰ã€‚
*   **`ScoreHead` (Class)**: è½»é‡çº§å›å½’å¤´ï¼Œç»“æ„ï¼š`LayerNorm â†’ Linear(Hâ†’H/4) â†’ GELU â†’ Linear(H/4â†’1)`ã€‚
*   **`ScoringActor` (Class)**:
    *   **Mismatch Mask**: åœ¨ Forward ä¸­ï¼Œå¼ºåˆ¶ Match ä½ç½®çš„ logit ä¸ºæå¤§æ¦‚ç‡ (50.0)ï¼Œç¡®ä¿ Ground Truth å¿…å®šè¢« Acceptã€‚
    *   **è‡ªåŠ¨åŠ è½½ Peft Adapter**: æ”¯æŒä» `adapter_path` åŠ è½½ LoRA + ScoreHead æƒé‡ã€‚
*   **`AutoModelForSPDScoring` (Class)**: å·¥å‚ç±»ï¼Œæ¨¡æ‹Ÿ `AutoModel` æ¥å£ï¼Œä½œä¸º verl åŠ è½½æµç¨‹çš„é€‚é…å™¨ã€‚
*   **è¾…åŠ©å‡½æ•°**: `create_hybrid_attention_mask`, `create_spd_attention_mask`, `create_position_ids` ç­‰ï¼Œç”¨äºæ„é€  SPD åœºæ™¯çš„ 4D Attention Maskã€‚

### 2. æ‰§è¡Œå±‚: `verl/workers/rollout/spd_rollout.py`

æ­¤æ–‡ä»¶å®ç°äº† SPD ä¸“ç”¨çš„ Rollout ç­–ç•¥ï¼Œ**æ˜¯æ•´ä¸ª SPD Scorer çš„æ ¸å¿ƒæ‰§è¡Œæ¨¡å—**ã€‚

*   **`VllmEngineServer` (Class)**: vLLM HTTP å®¢æˆ·ç«¯ï¼Œé€šè¿‡ REST API è°ƒç”¨ vLLM æœåŠ¡å™¨è¿›è¡Œè¡¥å…¨ã€‚
*   **`SPDRollout` (Class)**:
    *   ç»§æ‰¿è‡ª `BaseRollout`ã€‚
    *   **å¤š vLLM æœåŠ¡å™¨è´Ÿè½½å‡è¡¡**: æ ¹æ® `CUDA_VISIBLE_DEVICES` é€‰æ‹©å¯¹åº”çš„ vLLM æœåŠ¡å™¨ï¼ˆä» `SPD_VLLM_URLS` ç¯å¢ƒå˜é‡è¯»å–ï¼‰ã€‚
    *   **`generate_sequences`**: 
        1. Forward è·å– Accept æ¦‚ç‡
        2. æ¸©åº¦é‡‡æ · (`SPD_SAMPLE_TEMPERATURE`) æ§åˆ¶æ¢ç´¢å¼ºåº¦
        3. Bernoulli é‡‡æ ·ç”Ÿæˆ Accept/Reject åºåˆ—
        4. è®¡ç®—æœ‰æ•ˆé•¿åº¦ L (cumprod)
        5. **Heavy Rollout**: æ„é€  Hybrid Context å¹¶è°ƒç”¨ vLLM è¡¥å…¨éªŒè¯
        6. å°† `effective_len` å’Œ `is_correct_hybrid` æ³¨å…¥ `extra_info` ä¾› Reward ä½¿ç”¨
    *   **L=0 ç‰¹æ®Šå¤„ç†**: é€€åŒ–ä¸º Baselineï¼Œæ­£ç¡®æ€§ç­‰äº `is_correct_baseline`ã€‚

### 3. è¯„ä¼°å±‚: `verl/utils/reward_score/spd_scorer_reward.py`

æ­¤æ–‡ä»¶å®ç°äº†**è½»é‡çº§** Reward è®¡ç®—é€»è¾‘ã€‚

*   **è®¾è®¡è¯´æ˜**: 
    *   vLLM è¡¥å…¨éªŒè¯åœ¨ Rollout é˜¶æ®µå®Œæˆï¼ˆ`spd_rollout.py`ï¼‰
    *   Reward å‡½æ•°åªè´Ÿè´£è¯»å–ç»“æœå¹¶åº”ç”¨å¥–åŠ±å…¬å¼
*   **`compute_score` (Function)**:
    *   ä» `extra_info` è¯»å– `effective_len` (L)ã€`is_correct_hybrid` (S_h)ã€`is_correct_baseline` (S_t)
    *   **L=0 æ—¶ç›´æ¥è¿”å› 0** (ä¸å‚ä¸å­¦ä¹ )
    *   åº”ç”¨å››åœºæ™¯å¥–åŠ±å…¬å¼:
        - åœºæ™¯A: `S_t * S_h * (alpha * L)` â€” åŠ é€ŸæˆåŠŸ
        - åœºæ™¯B: `S_t * (1-S_h) * penalty_break` â€” ç ´åæ­£ç¡®
        - åœºæ™¯C: `(1-S_t) * (1-S_h) * reward_useless` â€” æ— ç”¨å°è¯•
        - åœºæ™¯D: `(1-S_t) * S_h * (reward_correct_base + alpha * L)` â€” çº æ­£é”™è¯¯

### 4. æ•°æ®å±‚: `verl/utils/dataset/spd_dataset.py`

è‡ªå®šä¹‰ Datasetï¼Œä¼˜åŒ–äº†æ•°æ®åŠ è½½æµç¨‹ã€‚

*   **`SPDRLHFDataset` (Class)**:
    *   è‡ªåŠ¨ä¿®æ­£ Left Padding å¸¦æ¥çš„ç´¢å¼•åç§» (åŒæ—¶ä¿®æ­£ `extra_info` å’Œ `rollout_info` ä¸­çš„ç´¢å¼•)ã€‚
    *   è·³è¿‡é»˜è®¤çš„ Chat Template å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨é¢„å¤„ç†å¥½çš„ `input_ids`ã€‚
    *   æ”¯æŒæˆªæ–­åˆ° `max_prompt_length` (åªä¿ç•™æœ€å N ä¸ª token)ã€‚

### 5. è®­ç»ƒå…¥å£: `train_spd_scorer.py`

è´Ÿè´£æ•°æ®å‡†å¤‡å’Œå¯åŠ¨è®­ç»ƒã€‚

*   **`setup_loguru_rank0`**: é…ç½® loguru åªè®© rank0 è¾“å‡º DEBUG/INFOã€‚
*   **Monkey Patch (å…³é”® Hack)**:
    *   **è¢«æ›¿æ¢å‡½æ•°**: `verl.utils.model.create_huggingface_actor`
    *   **æ›¿æ¢é€»è¾‘**: æ‹¦æˆªè°ƒç”¨ï¼Œè¿”å› `AutoModelForSPDScoring.from_config(...)` åˆ›å»ºçš„ `ScoringActor`ã€‚
*   **`prepare_spd_data_from_real_source`**: ä» SPD ç”Ÿæˆæ•°æ® + Metadata æ„é€ è®­ç»ƒæ•°æ®ã€‚
    *   æ„é€  `input_ids`: `[Context] + [SEP] + [Draft] + [SEP] + [Target] + [SEP]`
    *   è·³è¿‡ `draft_ids == target_ids[:-1]` çš„æ ·æœ¬ï¼ˆæ— å­¦ä¹ ä»·å€¼ï¼‰
*   **`build_training_command`**: æ„å»º verl GRPO è®­ç»ƒå‘½ä»¤ï¼ˆå«æ‰€æœ‰è¶…å‚æ•°ï¼‰ã€‚
*   **`_create_training_env`**: ç”Ÿæˆè®­ç»ƒç¯å¢ƒå˜é‡ï¼ˆReward ç³»æ•°ã€Model è·¯å¾„ã€SEP Token ID ç­‰ï¼‰ã€‚

### 6. è®­ç»ƒè„šæœ¬: `scripts/train_spd_scorer.sh` & `scripts/train_spd_scorer_info.sh`

Shell è„šæœ¬ï¼Œç”¨äºé…ç½®å’Œå¯åŠ¨è®­ç»ƒã€‚ä¸»è¦åŠŸèƒ½ï¼š

*   **ç¯å¢ƒæ¸…ç†**: è‡ªåŠ¨åœæ­¢æ®‹ç•™ Ray è¿›ç¨‹ï¼Œé˜²æ­¢è¿æ¥æ—§é›†ç¾¤ã€‚
*   **ç¯å¢ƒå˜é‡é…ç½®**: 
    - `CUDA_VISIBLE_DEVICES`: GPU å¯è§æ€§
    - `HF_HOME`, `HF_HUB_OFFLINE`: HuggingFace ç¼“å­˜é…ç½®
    - `SPD_VLLM_URLS`: vLLM æœåŠ¡å™¨ URL åˆ—è¡¨ (æ”¯æŒå¤šæœåŠ¡å™¨è´Ÿè½½å‡è¡¡)
*   **æ¨¡å‹é…ç½®**: `MODEL_PATH`, `TOKENIZER_PATH`, `ADAPTER_PATH`, LoRA å‚æ•°
*   **æ•°æ®é…ç½®**: æ•°æ®ç›®å½•ã€è®­ç»ƒæ•°æ®æ–‡ä»¶ã€å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
*   **è®­ç»ƒè¶…å‚æ•°**: Batch Size, Rollout N, Epochs, PPO Mini Batch Size ç­‰
*   **å¥–åŠ±é…ç½®**: `REWARD_ALPHA`, `REWARD_PENALTY_BREAK`, `REWARD_CORRECT_BASE`, `REWARD_USELESS`

åŒºåˆ«: `train_spd_scorer.sh` ä½¿ç”¨ `LOGURU_LEVEL=DEBUG`ï¼Œ`train_spd_scorer_info.sh` ä½¿ç”¨ `LOGURU_LEVEL=INFO`ã€‚

### 7. æ³¨å†Œä¿®æ”¹ (åŸæœ‰æ–‡ä»¶)

ä¸ºäº†è®© verl è¯†åˆ«ä¸Šè¿°è‡ªå®šä¹‰æ¨¡å—ï¼Œå¯¹åŸæœ‰æ–‡ä»¶è¿›è¡Œäº†å°‘é‡ä¿®æ”¹ï¼š

*   **`verl/utils/reward_score/__init__.py`**: åœ¨ `default_compute_score` ä¸­å¢åŠ äº† `spd_scorer` åˆ†æ”¯ã€‚
*   **`verl/workers/rollout/base.py`**: æ³¨å†Œäº† `("spd", "sync")` Rolloutã€‚
*   **`verl/trainer/ppo/ray_trainer.py`**: 
    - æ·»åŠ  Debug æ—¥å¿—ï¼šæ‰“å° Batch Size å˜åŒ–
    - **å…³é”®ä¿®æ”¹**: `_get_gen_batch()` æ–¹æ³•ç§»é™¤äº†å¯¹ `extra_info` çš„è¿‡æ»¤ï¼Œä½¿å…¶èƒ½ä¼ é€’ç»™ Rollout é˜¶æ®µï¼ˆæ³¨é‡Šæ ‡è®° `[SPD Fix]`ï¼‰
*   **`verl/workers/actor/dp_actor.py`**: æ·»åŠ  loguru è°ƒè¯•æ—¥å¿—ï¼Œè¾“å‡º Actor æ›´æ–°è¿‡ç¨‹ä¸­çš„å…³é”®æŒ‡æ ‡ï¼š
    - Micro Batch ä¿¡æ¯: `response_mask`, `old_log_prob`, `advantages` ç»Ÿè®¡
    - å½“å‰æ¨¡å‹ `log_prob` ä¸ `old_log_prob` å·®å¼‚ (ç­–ç•¥åç§»è§‚å¯Ÿ)
    - Policy Loss, Entropy Loss, KL Loss ç­‰æŸå¤±å€¼
    - Gradient Norm å’Œæœ€ç»ˆè®­ç»ƒæŒ‡æ ‡æ±‡æ€»
*   **`verl/workers/reward_manager/batch.py`**: ä¿®æ”¹ `BatchRewardManager.verify()` æ–¹æ³•ï¼Œä¼ é€’å®Œæ•´ Batch Tensorï¼š
    ```python
    scores = self.compute_score(
        ...
        # æ–°å¢å‚æ•°
        prompt_ids=prompt_ids,
        response_ids=response_ids,
        attention_mask=attention_mask,
        batch_tensors=data.batch,  # å®Œæ•´ batch ä¾› SPD Scorer ä½¿ç”¨
        **self.reward_kwargs,
    )
    ```

---

## ğŸš€ è®­ç»ƒæµç¨‹æ€»ç»“

1.  **å¯åŠ¨**: è¿è¡Œ `bash scripts/train_spd_scorer.sh` (æˆ– `train_spd_scorer_info.sh`)ã€‚
2.  **Patch**: è„šæœ¬é¦–å…ˆåº”ç”¨ Monkey Patchï¼ŒåŠ«æŒæ¨¡å‹åŠ è½½é€»è¾‘ã€‚
3.  **åŠ è½½**: verl Trainer è°ƒç”¨ `create_huggingface_actor`ï¼Œè¢«é‡å®šå‘åˆ° `AutoModelForSPDScoring`ï¼ŒåŠ è½½ `ScoringActor`ã€‚
4.  **æ•°æ®**: `SPDRLHFDataset` åŠ è½½æ•°æ®å¹¶ä¿®æ­£ç´¢å¼•ã€‚
5.  **Rollout**: `SPDRollout` æ‰§è¡Œ Forward â†’ Bernoulli é‡‡æ · â†’ vLLM Hybrid è¡¥å…¨éªŒè¯ã€‚
6.  **Reward**: `spd_scorer_reward` åŸºäºæœ‰æ•ˆé•¿åº¦å’Œæ­£ç¡®æ€§è®¡ç®—å¥–åŠ±ã€‚
7.  **æ›´æ–°**: GRPO æ›´æ–°æ¨¡å‹å‚æ•° (Actor æ›´æ–°è¿‡ç¨‹æœ‰è¯¦ç»†æ—¥å¿—)ã€‚
